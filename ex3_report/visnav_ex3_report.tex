\documentclass[12pt,a4paper]{article}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry} % less blank area
\usepackage{amsmath,amssymb,bm,dsfont} % for math
\usepackage{array}   % for eqnarray
\usepackage{arydshln}
\usepackage{graphicx}
\usepackage{enumerate} % for stylish enumrate
\usepackage{listings} % for code demonstration
\usepackage{color}    % for code highlight
\usepackage{fancyhdr} % for header and footnote
\usepackage{lastpage} % for calculating total pages
\usepackage{subfig} % for subfigure
\usepackage{tikz} % for drawing
\usepackage{pdfpages} % for importing PDF files

\newcommand{\docTitle}{IN2106 Practical Course -- Vision-based Navigation: Exercise \#3}
\newcommand{\docAuthor}{Min-An Chao (03681062)}
\newcommand{\docAuthorDept}{TUM MS Informatics}
\newcommand{\docAuthorEmail}{ga83fok@mytum.de}
\newcommand{\docDate}{06.05.2018}

\pagestyle{fancy}
\fancyhf{}
\lhead{\textit{\docTitle}}
\rhead{\textit{\docAuthor}}
\cfoot{\textit{- Page \thepage of \pageref{LastPage} -}}

\lstset{ language={},
         basicstyle=\ttfamily\footnotesize,
         keywordstyle=\color{blue}\ttfamily\footnotesize,
         commentstyle=\color{magenta}\ttfamily\footnotesize,
         morecomment=[l][\color{magenta}\footnotesize]{\#}
}

\setlength{\parindent}{0cm}
\setlength{\parskip}{0.5cm}

% for vector and matrix
\newcommand{\vct}[1]{\boldsymbol{#1}}
\newcommand{\mtx}[1]{\mathbf{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\dom}[1]{\mathbb{#1}}
\newcommand{\fnc}[1]{\text{#1}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

% for alignment argument of matrix/pmatrix
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother

\begin{document}
    \title{\vspace{-1.75cm} \large \textsf{\textbf{\docTitle}}}
    \author{\normalsize \textsf{
        \textbf{\docAuthor} \hspace{6pt}\textbar\hspace{6pt}
        \docAuthorDept \hspace{6pt}\textbar\hspace{6pt}
        \docAuthorEmail}}
    \date{\small \textsf{\docDate}}
    \maketitle 
    \thispagestyle{fancy}
    \vspace{-0.5cm}
    \hrule

    \section{Batch MAP}
    
    \textsf{\textbf{Task 1}}
    By taking $k=0,1,2$ into the system model,
    We can obtain
    \begin{eqnarray}\label{eq:h_matrix}
      \mtx{H} =
      \begin{pmatrix}[r]
        -1 &  1 &  0 & 0 \\
         0 & -1 &  1 & 0 \\
         0 &  0 & -1 & 1 \\
         0 &  1 &  0 & 0 \\
         0 &  0 &  1 & 0 \\
         0 &  0 &  0 & 1
      \end{pmatrix}.
    \end{eqnarray}

    \textsf{\textbf{Task 2}}
    From the system model and Eq.~\ref{eq:h_matrix},
    we have,
    \begin{eqnarray}\label{eq:n_vector}
      \vct{e} 
      = \vct{z} - \mtx{H}\vct{x}
      = \begin{pmatrix} v_1 \\ v_2 \\ v_3 \\ y_1 \\ y_2 \\ y_3 \end{pmatrix}
          -  \begin{pmatrix} x_1 - x_0 \\ x_2 - x_1 \\ x_3 - x_2 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix}
      = \begin{pmatrix} w_1 \\ w_2 \\ w_3 \\ n_1 \\ n_2 \\ n_3 \end{pmatrix}
      \sim \set{N}(\vct{0},\mtx{W}).
    \end{eqnarray}
    Obviously, if the noise is independent of each other, 
    we have
    \begin{eqnarray}\label{eq:n_vector}
      \mtx{W} = \fnc{diag}(Q,Q,Q,R,R,R),
    \end{eqnarray}
    otherwise $\mtx{W}$ could be any covariance matrix with
    this diagonal terms and other nonzero entries.

    \textsf{\textbf{Task 3}}
    Yes, if the noise is uncorrelated, then it is independent.
    In this case there is only one exact solution of $\mtx{W}$.

    \section{Iterative Curve Fitting}
    \textsf{\textbf{Task 1}}
    The derivatives of error to parameters could be obtained by
    \begin{eqnarray}\label{eq:cf_j}
      \vct{J}_i
      = \begin{pmatrix}
          \frac{\partial e_i}{\partial a} \\
          \frac{\partial e_i}{\partial b} \\
          \frac{\partial e_i}{\partial c}
        \end{pmatrix}
      = \begin{pmatrix}
          -f(x_i) \cdot x_i^2 \\
          -f(x_i) \cdot x_i \\
          -f(x_i) 
        \end{pmatrix},
    \end{eqnarray}
    where
    \begin{eqnarray}\label{eq:cf_f}
      f(x_i) = \fnc{exp}(a x_i^2 + b x_i + c).
    \end{eqnarray}
    Then we have
    \begin{eqnarray}\label{eq:cf_f}
      \mtx{H} &=& \sum_i \vct{J}_i \vct{J}_i^T, \nonumber\\
      \vct{b} &=& \sum_i - e_i \vct{J}_i, \nonumber\\
      (\Delta a, \Delta b, \Delta c)^T &=& \mtx{H}^{-1} \vct{b}.
    \end{eqnarray}
    By implementing this, we can see the results:
    \begin{lstlisting}[frame=single,numbers=left]
total cost: 3.19575e+06
total cost: 376785
total cost: 35673.6
total cost: 2195.01
total cost: 174.853
total cost: 102.78
total cost: 101.937
total cost: 101.937
total cost: 101.937
total cost: 101.937
total cost: 101.937
total cost: 101.937
cost: 101.937, last cost: 101.937
estimated abc = 0.890912, 2.1719, 0.943629
    \end{lstlisting}
    
    \textsf{\textbf{Task 2}}
    With \texttt{Google Ceres},
    first we have to implement the $e_i = y_i - f(x_i)$ part in
    the overloaded \texttt{()} function, \emph{i.e.}
    \texttt{operator()(const T *const abc, T *residual) const},
    inside the \texttt{CURVE\_FITTING\_COST} object.
    then we instantiate a \texttt{Problem} object,
    adding the cost function of the \texttt{CURVE\_FITTING\_COST} object
    into a \texttt{CostFunction} object
    by \texttt{AutoDiffCostFunction()} method,
    and using \texttt{Problem::AddResidualBlock()} method
    to add the residual block we have implemented inside
    the overloaded \texttt{()} function.
    Finally by the solver setups shown in lecture slides 
    and by the solver function call 
    we have the results:
    \begin{lstlisting}[frame=single,numbers=left]
iter      cost      cost_change  |gradient|   |step|    ... total_time
   0  1.597873e+06    0.00e+00    3.52e+06   0.00e+00   ...   1.17e-02
   1  1.884440e+05    1.41e+06    4.86e+05   9.88e-01   ...   1.66e-02
   2  1.784821e+04    1.71e+05    6.78e+04   9.89e-01   ...   1.99e-02
   3  1.099631e+03    1.67e+04    8.58e+03   1.10e+00   ...   2.29e-02
   4  8.784938e+01    1.01e+03    6.53e+02   1.51e+00   ...   2.58e-02
   5  5.141230e+01    3.64e+01    2.72e+01   1.13e+00   ...   2.79e-02
   6  5.096862e+01    4.44e-01    4.27e-01   1.89e-01   ...   2.98e-02
   7  5.096851e+01    1.10e-04    9.53e-04   2.84e-03   ...   3.17e-02
Ceres Solver Report: Iterations: 8, Initial cost: 1.597873e+06, 
Final cost: 5.096851e+01, Termination: CONVERGENCE
estimated a,b,c = 0.890908, 2.1719, 0.943628
    \end{lstlisting}

    \section{Camera Pose Estimation by Gauss-Newton Method}
    \textsf{\textbf{Task 1}}
    Suppose the rotation matrix of 
    the estimated pose $\mtx{T}_k$ is $\mtx{R}_k$
    and the translation part is $\vct{t}_k$,
    where $k$ stands for the iteration count.
    The projected position of 3D points $\vct{p}_i$ would be
    \begin{eqnarray}\label{eq:proj_pos}
      \vct{q}_{k,i} &=& \mtx{R}_{k-1} \vct{p}_i + \vct{t}_{k-1} \nonumber \\
      &=& (x_{k,i}, y_{k,i}, z_{k,i})^T.
    \end{eqnarray}
    The re-projection error $\vct{e}_{k,i}$ is obtained
    by applying the intrinsic matrix to the projected position
    with the normalization term $z_{k,i}$, or equally, ${q^{'}_{k,i}}^{(2)}$,
    which is,
    \begin{eqnarray}
      \vct{q}^{'}_{k,i} &=& \mtx{K}\vct{q}_{k,i}, \nonumber \\
      \vct{e}_{k,i} &=& \vct{u}_i -
        \frac{1}{ z_{k,i}} \cdot ({q^{'}_{k,i}}^{(0)}, {q^{'}_{k,i}}^{(1)})^T,
    \end{eqnarray}

    \textsf{\textbf{Task 2}}
    The Jacobian matrix of error could be derived,
    based on the slides,
    as
    \begin{eqnarray}
      \mtx{J}_{k,i} = \begin{pmatrix}
        -\frac{f_x}{z_{k,i}} & 0 & \frac{f_x  x_{k,i}}{z_{k,i}^2} & \frac{f_x  x_{k,i} y_{k,i}}{z_{k,i}^2} & -f_x - \frac{f_x  x_{k,i}^2}{z_{k,i}^2} & \frac{f_x y_{k,i}}{z_{k,i}} \\
        0 & -\frac{f_y}{z_{k,i}} & \frac{f_y  y_{k,i}}{z_{k,i}^2} & f_y + \frac{f_y  y_{k,i}^2}{z_{k,i}^2} & -\frac{f_y x_{k,i} y_{k,i}}{z_{k,i}^2} & -\frac{f_y x_{k,i}}{z_{k,i}} 
      \end{pmatrix},
    \end{eqnarray}
    where $x_{k,i}, y_{k,i}, z_{k,i}$ comes from Eq.~\ref{eq:proj_pos},
    and $f_x = K_{0,0}, f_y = K_{1,1}$.

    \textsf{\textbf{Task 3}}
    Updates on estimation pose are made iterative by
    \begin{eqnarray}
      \mtx{H}_k &=& \sum_i \vct{J}_{k,i}^T \vct{J}_{k,i}, \nonumber\\
      \vct{b}_k &=& \sum_i - \vct{J}_{k,i}^T \vct{e}_{k,i} , \nonumber\\
      \Delta \mtx{T}_k &=& \mtx{H}_k^{-1} \vct{b}_k, \nonumber\\
      \mtx{T}_k  &=& \exp((\Delta \mtx{T}_k)^{\wedge})  \mtx{T}_{k-1}.
    \end{eqnarray}
    $\Delta \mtx{T}_k$ here is expressed as a $\mathfrak{se}(3)$ 6-by-1 vector.
    Updates can be applied by calculating its exponential map, 
    and multiplying it to the previous pose $\mtx{T}_{k-1}$.
    The results are shown below.
    \begin{lstlisting}[frame=single,numbers=left]
points: 76
iteration 0 cost=45538.2
iteration 1 cost=413.209
iteration 2 cost=302.649
iteration 3 cost=301.357
iteration 4 cost=301.351
iteration 5 cost=301.351
iteration 6 cost=301.351
iteration 7 cost=301.351
iteration 8 cost=301.351
cost: 301.351, last cost: 301.351
estimated pose: 
  0.997866 -0.0516724  0.0399128  -0.127227
 0.0505959    0.99834  0.0275274 -0.0075068
-0.0412689 -0.0254492   0.998824  0.0613861
         0          0          0          1
    \end{lstlisting}

%% template for figures
%   \begin{figure}[!h]
%       \centering
%       \includegraphics[height=6cm]{fig/xxx.png}
%       \caption{XXX}
%       \label{fig:xxx}
%   \end{figure}
%% template for source code or results
%   \begin{lstlisting}[frame=single,numbers=left]
%   \end{lstlisting}
    
\end{document}
